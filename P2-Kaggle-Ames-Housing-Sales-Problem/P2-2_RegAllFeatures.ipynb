{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6fa8c6d-2e21-4e12-af69-4e52a2e983eb",
   "metadata": {},
   "source": [
    "# 3 Testing of Different Regression Permutations\n",
    "In this codebook, we will focus more on working through various logical and iterative steps to try and ascertain a good model for predicting the SalePrice of the Ames housing dataset.\n",
    "\n",
    "Our general 'modus operandi' will be as follows:\n",
    "1. Test the general model with all (relevant) features, and compare the usage of Ridge, Lasso, and vanilla linear regression.\n",
    "2. From the first test, we will determine which of the 3 has the best performance (most likely Lasso).\n",
    "3. We will test subsequent models with the best estimator strategy only to try and find the model with the best performance.\n",
    "4. Once we have settled on something, we will test the other estimators again.\n",
    "\n",
    "In this project, we will focus mostly on the impact specific variables have the accuracy of our model, and whether segments of the Ames dataset suggest that customers behave differently when certain conditions are met. This conjecture is based particularly on the economic concept of **market segmentation**, and how some groups of customers/buyers have different considerations and incentives to making a purchase, and thus have to be marketed to individually and differently.\n",
    "\n",
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49174e71-8c9d-45d0-a0b9-9862c240f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "# Sklearn modules\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b528bc68-e0af-4d91-b0c7-d4f32d692603",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aaabf16-4fda-48c2-b0ca-904e302c44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify Nominal Data\n",
    "def dummify_nom(NA,features_df,exclusion_list):\n",
    "    try:\n",
    "        # 1. nominal list with NAs - these will not need to drop their first column\n",
    "        if NA == 'withNA':\n",
    "            drop = False\n",
    "            tmp = feat_summ[(feat_summ['ftypes'] == 'Nominal') & # Nominal data\n",
    "                            ((feat_summ['train_null%'] == 0)&(feat_summ['test_null%'] == 0)) # No missing data\n",
    "                            ].index \n",
    "        # 2. nominal list without NAs - these will need to drop their first column\n",
    "        elif NA == 'withoutNA':\n",
    "            drop = True\n",
    "            tmp = feat_summ[(feat_summ['ftypes'] == 'Nominal') & # Nominal data\n",
    "                            ((feat_summ['train_null%'] > 0)|(feat_summ['test_null%'] > 0)) # No missing data\n",
    "                            ].index \n",
    "\n",
    "        tmp = [i for i in tmp if i not in exclusion_list]\n",
    "        \n",
    "        # Get dummies on nominal data, and apply it to features_df\n",
    "        return pd.get_dummies(features_df, columns = tmp, drop_first = drop)\n",
    "    except:\n",
    "        print(f'did not perform get_dummies on nominal data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fabeee4-de89-4b51-b4f1-5b2b5c567ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy columns for the columns missing in each, based on values not present in either\n",
    "def dummify_row_match(train_set,test_set):\n",
    "    train_set.loc[:,[i for i in test_set.columns if i not in train_set.columns]] = 0\n",
    "    test_set.loc[:,[i for i in train_set.columns if i not in test_set.columns]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dbfde1d-058b-4eb0-8dfd-d1d73596010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_row_match(train_set,test_set):\n",
    "    train_drop = []\n",
    "    test_drop = []\n",
    "    \n",
    "    # List of columns not present in each in the other\n",
    "    test_drop = [i for i in test_set.columns if i not in train_set.columns]\n",
    "    train_drop = [i for i in train_set.columns if i not in test_set.columns]\n",
    "    \n",
    "    # drop all columns not present in each\n",
    "    train_set_output = train_set.drop(train_drop, axis = 1)\n",
    "    test_set_output = test_set.drop(test_drop, axis = 1)\n",
    "    \n",
    "    return train_set_output, test_set_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e0708a-d2e3-4949-b107-d2ece2de5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for imputation and scaling\n",
    "# X_test_tar treatment is optional\n",
    "def basic_modelprep(imputer, X_train_tar, X_test_tar, X_hidden_tar, kaggleset = False):\n",
    "    # Impute Data\n",
    "    if imputer == 'simple':  \n",
    "        imp = SimpleImputer(strategy = 'mean')\n",
    "        X_train_tmp = pd.DataFrame(imp.fit_transform(X_train_tar))\n",
    "        X_test_tmp = pd.DataFrame(imp.transform(X_test_tar))\n",
    "        X_hidden_tmp = pd.DataFrame(imp.transform(X_hidden_tar))\n",
    "\n",
    "    # Scaling the data\n",
    "    ss = StandardScaler()\n",
    "    X_train_tmp = ss.fit_transform(X_train_tmp)\n",
    "    X_test_tmp = ss.transform(X_test_tmp)\n",
    "    X_hidden_tmp = ss.transform(X_hidden_tmp)\n",
    "    \n",
    "    return X_train_tmp, X_test_tmp, X_hidden_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4d268-aaad-457a-9899-9fd26bf8f7ed",
   "metadata": {},
   "source": [
    "## 3.1 Regularisation with All Features, using Lasso and Ridge\n",
    "We will use a standard regularisation with all features included as our benchmark for base model performance, and tweak our approach as we move forward from there. This methodology can be truly associated with the \"let the model do the work\" mindset, as we trust our regularisation and imputation algorithms to sift through the correlations and find the best predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e82c475f-86cc-4694-b323-b3b9e8cde40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('datasets/train_ord.csv', index_col = 'Unnamed: 0')\n",
    "test_df = pd.read_csv('datasets/test_ord.csv', index_col = 'Unnamed: 0')\n",
    "feat_summ = pd.read_csv('datasets/feature_summary.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f45608-84d1-496f-a8bc-6fdba84d8fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>533352170</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13517</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>544</td>\n",
       "      <td>531379050</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11492</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>535304180</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7922</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>318</td>\n",
       "      <td>916386060</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9802</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255</td>\n",
       "      <td>906425045</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14235</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>138500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street Alley  \\\n",
       "0  109  533352170           60        RL           NaN     13517   Pave   NaN   \n",
       "1  544  531379050           60        RL          43.0     11492   Pave   NaN   \n",
       "2  153  535304180           20        RL          68.0      7922   Pave   NaN   \n",
       "3  318  916386060           60        RL          73.0      9802   Pave   NaN   \n",
       "4  255  906425045           50        RL          82.0     14235   Pave   NaN   \n",
       "\n",
       "   Lot Shape Land Contour  ...  Screen Porch Pool Area  Pool QC Fence  \\\n",
       "0          2          Lvl  ...             0         0        0     0   \n",
       "1          2          Lvl  ...             0         0        0     0   \n",
       "2          3          Lvl  ...             0         0        0     0   \n",
       "3          3          Lvl  ...             0         0        0     0   \n",
       "4          2          Lvl  ...             0         0        0     0   \n",
       "\n",
       "  Misc Feature Misc Val Mo Sold Yr Sold  Sale Type  SalePrice  \n",
       "0          NaN        0       3    2010        WD      130500  \n",
       "1          NaN        0       4    2009        WD      220000  \n",
       "2          NaN        0       1    2010        WD      109000  \n",
       "3          NaN        0       4    2010        WD      174000  \n",
       "4          NaN        0       3    2010        WD      138500  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2a29e61-3ca9-446f-9a5e-19aaff466da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning X features, remove y and IDs from the list\n",
    "excl_list = ['SalePrice','Id','PID']\n",
    "features = [i for i in train_df.columns if i not in excl_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aede5249-56d7-4ecd-8b15-b4e60c993f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning X and y variables\n",
    "X = train_df[features]\n",
    "y = train_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f985ce6d-f4f6-4de7-8856-7adde12af38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[features] # The code returns a run error if run twice\n",
    "X = dummify_nom('withNA',X,excl_list)\n",
    "X = dummify_nom('withoutNA',X,excl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70ad83cd-3474-412b-a05c-5d5a21da485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hidden = test_df[features][:]\n",
    "X_hidden = dummify_nom('withNA',X_hidden,excl_list)\n",
    "X_hidden = dummify_nom('withoutNA',X_hidden,excl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3df4c92c-b31a-4f38-84d1-37ddafe54452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "# Keeping a random state so to maintain consistency between model runs\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a195e6-f7b8-456c-9a87-0d4548d2f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicating out train/test sets for this regression step\n",
    "X_train_1 = X_train[:]\n",
    "X_test_1 = X_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "765a5465-ceef-45a5-a1c2-a92f3cb319ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden features (X) for kaggle submission\n",
    "X_hidden_1 = X_hidden[:]\n",
    "\n",
    "# Remove any columns that do not exist in either the test set or the train set\n",
    "X_train_1, X_hidden_1 = drop_row_match(X_train_1, X_hidden_1)\n",
    "X_train_1, X_test_1 = drop_row_match(X_train_1,X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c32a4fab-28d5-4577-b2a7-bcc193da624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlined imputation\n",
    "X_train_1, X_test_1, X_hidden_1 = basic_modelprep(imputer = 'simple', \n",
    "                                                  X_train_tar = X_train_1, \n",
    "                                                  X_test_tar = X_test_1,\n",
    "                                                  X_hidden_tar = X_hidden_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fe933d8-4530-41f6-b312-96f2e1209635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Regression models\n",
    "lr = LinearRegression()\n",
    "lasso = LassoCV(n_alphas = 200)\n",
    "ridge = RidgeCV(alphas = np.linspace(0.1,10,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952a0cac-46ef-4348-b78c-2ffe4a79d396",
   "metadata": {},
   "source": [
    "### 3.1.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ed732c9-9376-489b-872b-b061aab488b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9164062693935097e+20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Val Score for standard linear regression\n",
    "lr_score = cross_val_score(lr,X_train_1,y_train,cv=5)\n",
    "lr_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec611e-8b09-4bb9-b2fe-d772e38d2056",
   "metadata": {},
   "source": [
    "Very poignantly, the simple linear regression is abyssmally poor at predicting anything, thus we will be skipping evaluating a vanilla linear regression from now on.\n",
    "\n",
    "### 3.1.2 Linear Regression with Lasso Regularisation (Run 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88ad8b91-495a-4241-a496-fb4d3e57adfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8232714217330204"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LassoCV Score\n",
    "lasso_score = cross_val_score(lasso,X_train_1,y_train,cv=5)\n",
    "lasso_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9ca9a25-aa90-437a-be32-753398c8e34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8856330124618806\n",
      "0.8896044014377833\n"
     ]
    }
   ],
   "source": [
    "# LassoCV train vs test scores\n",
    "lasso.fit(X_train_1,y_train)\n",
    "print(lasso.score(X_train_1,y_train))\n",
    "print(lasso.score(X_test_1,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8852f825-81b8-41f1-9611-c1389dec0b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26035.201272306058"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LassoCV Rooted Mean Squared Error\n",
    "y_pred = lasso.predict(X_test_1)\n",
    "mean_squared_error(y_test,y_pred, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0e8c964-6316-41b6-a189-a211afc9e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pushing kaggle .csv submissions\n",
    "# y_pred results\n",
    "y_pred_kaggle = lasso.predict(X_hidden_1)\n",
    "y_312_pred_kaggle = y_pred_kaggle # Use for later\n",
    "\n",
    "# Setting up kaggle submission .csv\n",
    "kaggle_exp = pd.DataFrame({'Id':test_df['Id'],\n",
    "                           'SalePrice': y_pred_kaggle})\n",
    "kaggle_312_exp = kaggle_exp[:] # Use for later\n",
    "kaggle_exp.to_csv('Subm/lr_3_1_1_lasso_all_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647bdaed-0ee1-4caf-ac87-8c3d95c7d14b",
   "metadata": {},
   "source": [
    "### 3.1.3 Linear Regression with Ridge Regularisation (Run 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae6b370e-b669-448f-b87d-153af5672a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7798111325614392"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RidgeCV Score\n",
    "ridge_score = cross_val_score(ridge,X_train_1,y_train,cv=5)\n",
    "ridge_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5307ae5e-af4c-4466-88df-fa535a5f017b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9089554587068819\n",
      "0.8704728499744766\n"
     ]
    }
   ],
   "source": [
    "# RidgeCV train vs test scores\n",
    "ridge.fit(X_train_1,y_train)\n",
    "print(ridge.score(X_train_1,y_train))\n",
    "print(ridge.score(X_test_1,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d927a68d-4ceb-4578-9609-db2e5f183414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28201.062114810604"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RidgeCV Rooted Mean Squared Error\n",
    "y_pred = ridge.predict(X_test_1)\n",
    "mean_squared_error(y_test,y_pred, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "363e901b-218c-46e9-a0bd-ddcb0a2c468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pushing kaggle .csv submissions\n",
    "# y_pred results\n",
    "y_pred_kaggle = ridge.predict(X_hidden_1)\n",
    "\n",
    "# Setting up kaggle submission .csv\n",
    "kaggle_exp = pd.DataFrame({'Id':test_df['Id'],\n",
    "                           'SalePrice': y_pred_kaggle})\n",
    "kaggle_exp.to_csv('Subm/lr_3_1_2_ridge_all_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d818731d-1237-4b71-8169-06ec06fda8c7",
   "metadata": {},
   "source": [
    "### 3.1.4 Conclusions\n",
    "The summary of results is as follows:\n",
    "1. Linear Regression (R2): $-1.9 * 10^{20}$\n",
    "2. LassoCV Regression (R2): $0.88$\n",
    "3. RidgeCV Regression (R2): $0.87$\n",
    "\n",
    "Comparing RMSE values:\n",
    "1. LassoCV (RSME): $26,035.20$\n",
    "2. RidgeCV (RSME): $28,201.06$\n",
    "\n",
    "From the above results, Lasso seems to be slightly better in this respect, though the two methods aren't that dissimiliar in output. As this is just the first iteration, the RSME sits at a hefty ~35k.\n",
    "\n",
    "Also note that each re-run of the codebook will yield different results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e7367e-4a54-4178-88d0-34f8c487238b",
   "metadata": {},
   "source": [
    "### 3.1.5 Impact of Removing Fields with High Nulls (Run 3)\n",
    "In our data cleaning and EDA section, we identified some fields, namely 'Alley', 'Pool QC', 'Fence', and 'Misc Feature', which had very high null counts. The below section will test the effect of such fields being included in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9886f40-d97e-4360-a754-4a1f5c4ce15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "excl_list = ['SalePrice','Id','PID','Alley','Pool QC','Fence','Misc Feature']\n",
    "excl_list_mod = [j for j in X_train.columns for i in excl_list if i in j]  \n",
    "features = [i for i in X_train.columns if i not in excl_list_mod]\n",
    "X_train_2 = X_train[features]\n",
    "X_test_2 = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47dfbca0-af8c-4821-afc6-6f7c6aca4fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_hidden = [i for i in features if i in X_hidden.columns]\n",
    "X_hidden_2 = X_hidden[features_hidden]\n",
    "\n",
    "# Remove any columns that do not exist in either the test set or the train set\n",
    "X_train_2, X_hidden_2 = drop_row_match(X_train_2, X_hidden_2)\n",
    "X_train_2, X_test_2 = drop_row_match(X_train_2,X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc2217f2-7afd-41ac-a83b-cfda503bb2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2,X_test_2,X_hidden_2 = basic_modelprep('simple',X_train_2,X_test_2, X_hidden_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59b6cd0f-d854-427e-99fc-37ec14115ce8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8286941584958025"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV(n_alphas = 200) # instantiate\n",
    "lasso_score = cross_val_score(lasso,X_train_2,y_train,cv=5)\n",
    "lasso_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b26cd372-afaa-49fd-a5b2-8204a90368bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8869334530211209\n",
      "0.8953275180946924\n"
     ]
    }
   ],
   "source": [
    "lasso.fit(X_train_2,y_train)\n",
    "print(lasso.score(X_train_2,y_train))\n",
    "print(lasso.score(X_test_2,y_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b6dd181-e2b6-4fee-ad76-3ba8cd96678c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25351.363424510546"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LassoCV Rooted Mean Squared Error\n",
    "y_pred = lasso.predict(X_test_2)\n",
    "mean_squared_error(y_test,y_pred, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4fb48a-9ebe-488f-9d0a-a446c94ce3c8",
   "metadata": {},
   "source": [
    "The above results show that removing the high null fields yield negligible change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3352c772-e565-41bd-ab9a-03e9686375c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pushing kaggle .csv submissions\n",
    "# y_pred results\n",
    "y_pred_kaggle = lasso.predict(X_hidden_2)\n",
    "\n",
    "# Setting up kaggle submission .csv\n",
    "kaggle_exp = pd.DataFrame({'Id':test_df['Id'],\n",
    "                           'SalePrice': y_pred_kaggle})\n",
    "kaggle_exp.to_csv('Subm/lr_3_1_3_lasso_remove_high_null.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f8c61-4c4d-4519-b659-cfab417384d5",
   "metadata": {},
   "source": [
    "## 3.2 Regression with only features with $>50%$ correlation with SalePrice (Run 4)\n",
    "As we start to narrow down regression tactics, one obvious choice is to choose only those fields strongly correlated to the SalePrice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5412f24-f382-49cc-a5c2-062ef8774585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify train_df and get all the fields with high correlation to SalePrice\n",
    "train_df_dummy = train_df[:]\n",
    "train_df_dummy = dummify_nom('withNA',train_df_dummy,['Id','PID'])\n",
    "train_df_dummy = dummify_nom('withoutNA',train_df_dummy,['Id','PID'])\n",
    "high_corr_list = train_df_dummy.corr()[\n",
    "    (train_df_dummy.corr()['SalePrice'] > 0.5)| # Include only correlation higher than 50%\n",
    "    (train_df_dummy.corr()['SalePrice'] < -0.5)].index # and lower than -50%\n",
    "high_corr_list = [i for i in high_corr_list if i != 'SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30b3b248-6c45-4f39-81ff-240743d3f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying our X_train and X_test to fit the confines of the problem\n",
    "X_train_3 = X_train[high_corr_list]\n",
    "X_test_3 = X_test[high_corr_list]\n",
    "X_hidden_3 = X_hidden[high_corr_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "072c318a-8c02-48fe-a5bc-fe07c2f1ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, X_test_3, X_hidden_3 = basic_modelprep('simple',X_train_3,X_test_3,X_hidden_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5973b0d4-8f0b-46b6-b3b1-e4cb5e1fed78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7871675077111492"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV(n_alphas = 200) # instantiate\n",
    "lasso_score = cross_val_score(lasso,X_train_3,y_train,cv=5)\n",
    "lasso_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b046c07-80cd-4b0d-965f-3b7c3ecac216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8056102360231014\n",
      "0.8609787542615951\n"
     ]
    }
   ],
   "source": [
    "lasso.fit(X_train_3,y_train)\n",
    "print(lasso.score(X_train_3,y_train))\n",
    "print(lasso.score(X_test_3,y_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46f7f095-af75-44e5-a468-f2e44725522e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29216.329113569987"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LassoCV Rooted Mean Squared Error\n",
    "y_pred = lasso.predict(X_test_3)\n",
    "mean_squared_error(y_test,y_pred, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfc1863e-50ca-4e4a-bb83-2f92d99ff9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pushing kaggle .csv submissions\n",
    "# y_pred results\n",
    "y_pred_kaggle = lasso.predict(X_hidden_3)\n",
    "\n",
    "# Setting up kaggle submission .csv\n",
    "kaggle_exp = pd.DataFrame({'Id':test_df['Id'],\n",
    "                           'SalePrice': y_pred_kaggle})\n",
    "kaggle_exp.to_csv('Subm/lr_3_1_4_lasso_high_corr.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7dfbfc-4c04-439b-a646-f0898424eb8b",
   "metadata": {},
   "source": [
    "### 3.2.1 Trying removing high null fields again from 3.2 (Run 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca283837-7d48-46ea-bf33-84ab43ac3a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "excl_list = ['SalePrice','Id','PID','Alley','Pool QC','Fence','Misc Feature']\n",
    "excl_list_mod = [j for j in X_train[high_corr_list].columns for i in excl_list if i in j]  \n",
    "features = [i for i in X_train[high_corr_list] if i not in excl_list_mod]\n",
    "\n",
    "X_train_4 = X_train[high_corr_list][features]\n",
    "X_test_4 = X_test[high_corr_list][features]\n",
    "X_hidden_4 = X_hidden[high_corr_list][features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ce391f0-5c6f-4f41-8159-d64c5e13638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4, X_test_4, X_hidden_4 = basic_modelprep('simple',X_train_4, X_test_4, X_hidden_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc0f9b85-4c08-4927-a4db-6aedae8d135a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7871675077111492"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV(n_alphas = 200) # instantiate\n",
    "lasso_score = cross_val_score(lasso,X_train_4,y_train,cv=5)\n",
    "lasso_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a39ee686-e266-4095-8a0f-a4013c821722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8056102360231014\n",
      "0.8609787542615951\n"
     ]
    }
   ],
   "source": [
    "lasso.fit(X_train_4,y_train)\n",
    "print(lasso.score(X_train_4,y_train))\n",
    "print(lasso.score(X_test_4,y_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fd9e81e-1cdf-4296-baba-fb42b9afde19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29216.329113569987"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LassoCV Rooted Mean Squared Error\n",
    "y_pred = lasso.predict(X_test_4)\n",
    "mean_squared_error(y_test,y_pred, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0233caa-c11f-4e45-b4e3-28197c9816f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pushing kaggle .csv submissions\n",
    "# y_pred results\n",
    "y_pred_kaggle = lasso.predict(X_hidden_4)\n",
    "\n",
    "# Setting up kaggle submission .csv\n",
    "kaggle_exp = pd.DataFrame({'Id':test_df['Id'],\n",
    "                           'SalePrice': y_pred_kaggle})\n",
    "kaggle_exp.to_csv('Subm/lr_3_1_5_lasso_high_corr_remove_high_null.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f197b6c-5117-4b41-9b09-aee7a08e402f",
   "metadata": {},
   "source": [
    "**Conclusions**  \n",
    "From the above results, it is apparent that focusing entirely on the highly correlated features does not naturally translate into a more accurate model. In this case, we actually see a reduction in model performance of around 29,000, up from 26,000 from lasso all features run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab32f088-9250-4926-b147-9839884555a3",
   "metadata": {},
   "source": [
    "## 3.3 Looking into key features as metrics for segmentation\n",
    "In economics, rarely will you find market demand and supply that is consistent across various market segments. Be it by socio-economic class, geography, or other social factors, customer behaviour may vary wildly and in ways that may not be very easy to predict.  \n",
    "\n",
    "In application, this would mean we can assume that these market segments would have different relationships with the price (which is our metric for market equilibrium, so to speak), and thus would have different correlation/regressive characteristics.\n",
    "\n",
    "In this section, we will look at identifying some categorical fields to use as proxies to 'split' out dataset up, and generate separate models to predict their movements.\n",
    "\n",
    "The methodology for selecting fields can be found in the EDA portion of this project.\n",
    "\n",
    "We will be looking mainly at the following choice fields:\n",
    "1. Lot Shape - Irregular (0) and Regular (1);\n",
    "2. Overall Quality - 1-5 (0), 6-7 (1), 8-10 (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b871cd1d-e1d0-4483-a565-fada874786da",
   "metadata": {},
   "source": [
    "### 3.3.1 Lot Shape (Run 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e467b579-ec31-4b9f-bfe4-a760b2e1b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for lot shape conversion\n",
    "def lot_shape_conv(df):\n",
    "    return [1 if i == 3 else 0 for i in df['Lot Shape']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aebfa457-daa9-4903-a9a9-c8524cd776c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Lot Shape into 0 (Irregular) and 1 (Regular)\n",
    "X_ls = X[:]\n",
    "X_hidden_ls = X_hidden[:]\n",
    "if 3 in list(X['Lot Shape']): # Make sure the code does not execute if already transformed\n",
    "    X_ls['Lot Shape'] = lot_shape_conv(X_ls)\n",
    "    X_hidden_ls['Lot Shape'] = lot_shape_conv(X_hidden_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e16a51f-8ab1-4da8-a334-d98c7fdcdd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the X and y into the Lot Shape subsets\n",
    "# Lot Shape = 0 (Irregular)\n",
    "X0 = X_ls[X_ls['Lot Shape'] == 0]\n",
    "y0 = y[X0.index]\n",
    "X0_hidden = X_hidden_ls[X_hidden_ls['Lot Shape'] == 0]\n",
    "\n",
    "#Lot Shape = 1 (Regular)\n",
    "X1 = X_ls[X_ls['Lot Shape'] == 1]\n",
    "y1 = y[X1.index]\n",
    "X1_hidden = X_hidden_ls[X_hidden_ls['Lot Shape'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65422701-a841-4142-b3fc-35c08c166f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split for both subsets\n",
    "X0_train, X0_test, y0_train, y0_test = train_test_split(X0,y0,random_state = 42)\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1,y1,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22640e25-b4e9-4302-969a-c7a45052cc99",
   "metadata": {},
   "source": [
    "#### 3.3.1.1 Lot Shape = 0; Regression (Lasso Reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad93a4ec-6ca0-438a-9578-689ebb4e2228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8685281612187381"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any columns that do not exist in either the test set or the train set\n",
    "X0_train, X0_hidden = drop_row_match(X0_train, X0_hidden)\n",
    "X0_train, X0_test = drop_row_match(X0_train,X0_test)\n",
    "\n",
    "# Simple Imputation + Standard Scaler\n",
    "X0_train, X0_test, X0_hidden = basic_modelprep('simple',X0_train,X0_test,X0_hidden)\n",
    "\n",
    "lasso = LassoCV(n_alphas = 200) # instantiate\n",
    "lasso_score = cross_val_score(lasso,X0_train,y0_train,cv=5)\n",
    "lasso_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2c9fb86-e12d-416c-bd30-25853c4c3894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9059705492030885\n",
      "0.24571922493554366\n"
     ]
    }
   ],
   "source": [
    "lasso.fit(X0_train,y0_train)\n",
    "print(lasso.score(X0_train,y0_train))\n",
    "print(lasso.score(X0_test,y0_test)) \n",
    "# This is an abyssmally bad score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3305c3e9-78ef-4b5f-9c95-69918583d2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70627.2540937239"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LassoCV Rooted Mean Squared Error\n",
    "y0_pred = lasso.predict(X0_test)\n",
    "mean_squared_error(y0_test,y0_pred, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "785ca6f6-0951-4bf1-b6ca-1cef182c286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle y-pred result\n",
    "y0_pred_kaggle = lasso.predict(X0_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b860620-5f66-4f99-bd3e-f533c2582e27",
   "metadata": {},
   "source": [
    "#### 3.3.1.2 Lot Shape = 1, Regression (Lasso Reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f2fcf9b-723b-493a-9686-7e244ca505ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9085348625083224"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any columns that do not exist in either the test set or the train set\n",
    "X1_train, X1_hidden = drop_row_match(X1_train, X1_hidden)\n",
    "X1_train, X1_test = drop_row_match(X1_train,X1_test)\n",
    "\n",
    "# Simple Imputation + Standard Scaler\n",
    "X1_train, X1_test, X1_hidden = basic_modelprep('simple',X1_train,X1_test,X1_hidden)\n",
    "\n",
    "lasso = LassoCV(n_alphas = 200) # instantiate\n",
    "lasso_score = cross_val_score(lasso,X1_train,y1_train,cv=5)\n",
    "lasso_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f21fa30-a15c-4a78-b99e-c61f85c36ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9341604340943529\n",
      "0.8886041685265025\n"
     ]
    }
   ],
   "source": [
    "lasso.fit(X1_train,y1_train)\n",
    "print(lasso.score(X1_train,y1_train))\n",
    "print(lasso.score(X1_test,y1_test)) \n",
    "# This is a really good score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21c9304f-3625-4af0-90ba-fc5363e7d235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18962.411674414358"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LassoCV Rooted Mean Squared Error\n",
    "y1_pred = lasso.predict(X1_test)\n",
    "mean_squared_error(y1_test,y1_pred, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "064d764c-f568-4144-99b5-e56715703aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle y-pred result\n",
    "y1_pred_kaggle = lasso.predict(X1_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71802d16-df6c-4e3e-b59d-cdff7df4f08f",
   "metadata": {},
   "source": [
    "#### 3.3.1.3 Combining the predictions into a .csv to submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f774f637-127b-4ee6-b936-3bde9227f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a roundabout way of preserving the Id mapping for the SalePrice\n",
    "X0_tmp = X_hidden_ls[X_hidden_ls['Lot Shape'] == 0][['Lot Shape']]\n",
    "X0_tmp['Id'] = test_df['Id']\n",
    "X0_tmp = X0_tmp[['Id']]\n",
    "X0_tmp['SalePrice'] = y0_pred_kaggle\n",
    "\n",
    "X1_tmp = X_hidden_ls[X_hidden_ls['Lot Shape'] == 1][['Lot Shape']]\n",
    "X1_tmp['Id'] = test_df['Id']\n",
    "X1_tmp = X1_tmp[['Id']]\n",
    "X1_tmp['SalePrice'] = y1_pred_kaggle\n",
    "\n",
    "X_tmp = pd.concat([X0_tmp,X1_tmp]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00f354c5-3a9e-4736-baf5-45db2e3cc87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pushing kaggle .csv submissions\n",
    "# Setting up kaggle submission .csv\n",
    "kaggle_exp = X_tmp\n",
    "kaggle_exp.to_csv('Subm/lr_3_3_1_Groupby_LotShape.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823ea32-318b-4466-85b0-f823fcde81e1",
   "metadata": {},
   "source": [
    "#### Conclusion to Lot Shape Groupings\n",
    "Summarising the findings from this iteration:\n",
    "1. The portion of the set that is irregular (grouping IR3/IR2/IR1 classifications into a single group) has really quite bad accuracy, giving us a 0.90/0.24 split in $R^2$ between the train and test sets.\n",
    "2. Conversely, the model is exceptionally good at predicting the regular lot shape classification.\n",
    "3. Overall (from kaggle), the composite segmented model produces **a respectable y-pred of 21,556 (private score).**\n",
    "\n",
    "This R^2 is likely the result of extremely good predictions from the Lot Shape = 1 side of the set, diluted by some inaccurate predictions from the Lot Shape = 0 subset.\n",
    "\n",
    "As an experiment, we will substitute the y-predictions for Lot Shape =0 with the y-pred from 3.1.2 (Lasso Regularisation benchmark), which was our best score before this, and see how that improves the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e4742ab-0136-474c-878f-c2646c745df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redoing the X_tmp setup, but replacing the y-pred data with that from 3.1.2\n",
    "X0_tmp = X_hidden_ls[X_hidden_ls['Lot Shape'] == 0][['Lot Shape']]\n",
    "X0_tmp['Id'] = test_df['Id']\n",
    "X0_tmp = X0_tmp[['Id']]\n",
    "X0_tmp['SalePrice'] = kaggle_312_exp['SalePrice'] # From 3.1.2\n",
    "\n",
    "X1_tmp = X_hidden_ls[X_hidden_ls['Lot Shape'] == 1][['Lot Shape']]\n",
    "X1_tmp['Id'] = test_df['Id']\n",
    "X1_tmp = X1_tmp[['Id']]\n",
    "X1_tmp['SalePrice'] = y1_pred_kaggle\n",
    "\n",
    "X_tmp = pd.concat([X0_tmp,X1_tmp]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "912ee359-18c3-4adb-bd18-c950a5ba9965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pushing kaggle .csv submissions\n",
    "# Setting up kaggle submission .csv\n",
    "kaggle_exp = X_tmp\n",
    "kaggle_exp.to_csv('Subm/lr_3_3_1_Groupby_LotShape_subwprev.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7201a5-07d5-445e-b1de-1b058bfa1714",
   "metadata": {},
   "source": [
    "Peculiarly, the substitution does not improve the score, and even worsens it a little (Private score of 22,134). The effect of which perhaps can be revisited and studied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960c77e-da95-4b7f-bc50-9fb1087267bd",
   "metadata": {},
   "source": [
    "### 3.3.2 Overall Quality (Run 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "014337fb-607c-471d-8df9-ea204fc3d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X and y variables (and X_hidden) to new scale factors\n",
    "X_OQ = X[:]\n",
    "X_hidden_OQ = X_hidden[:]\n",
    "\n",
    "def OQ_conv(df):\n",
    "    return [2 if i > 7 else 0 if i < 6 else 1 for i in df['Overall Qual']]\n",
    "\n",
    "X_OQ['Overall Qual'] = OQ_conv(X_OQ)\n",
    "X_hidden_OQ['Overall Qual'] = OQ_conv(X_hidden_OQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4e29a35-b8a7-4368-952a-29961aad1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into subsets\n",
    "def OQ_split(df,rank):\n",
    "    return df[df['Overall Qual'] == rank]\n",
    "\n",
    "# Xi_OQ and Xi_hidden_OQ sets\n",
    "for i in [0,1,2]:\n",
    "    globals()['X'+str(i)+'_OQ'] = OQ_split(X_OQ,i) # Convert X subsets\n",
    "    globals()['X'+str(i)+'_hidden_OQ'] = OQ_split(X_hidden_OQ,i) # Convert X_hidden subsets\n",
    "\n",
    "#yi_OQ sets\n",
    "for i in [0,1,2]:\n",
    "    globals()['y'+str(i)+'_OQ'] = y[globals()['X'+str(i)+'_OQ'].index] # Split out y variables as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e025552-0c14-4c61-87fa-b6e6bbff38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split for all subsets\n",
    "for i in [0,1,2]:\n",
    "    (globals()['X'+str(i)+'_train'], \n",
    "    globals()['X'+str(i)+'_test'], \n",
    "    globals()['y'+str(i)+'_train'], \n",
    "    globals()['y'+str(i)+'_test']) = train_test_split(globals()['X'+str(i)+'_OQ'],\n",
    "                                                     globals()['y'+str(i)+'_OQ'],\n",
    "                                                     random_state = 42)\n",
    "\n",
    "# There are now 3 sets of Xi_train and Xi_test, and yi_train and yi_test sets, for each of the 3 segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed3b27-78cd-47b1-ae6c-a9a98ce4fcc3",
   "metadata": {},
   "source": [
    "#### 3.3.2.0 Section Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08abe60b-cb24-4992-98d7-41476cfeaeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_modifiers(rank,str1 = None):\n",
    "    if str1 != None: str1 = '_' + str1\n",
    "    else: str1 = ''\n",
    "# Remove any columns that do not exist in either the test set or the train set\n",
    "    (globals()['X'+str(rank)+'_train'], \n",
    "     globals()['X'+str(rank)+'_hidden'+str1]) = drop_row_match(globals()['X'+str(rank)+'_train'], \n",
    "                                                               globals()['X'+str(rank)+'_hidden'+str1])\n",
    "    (globals()['X'+str(rank)+'_train'], \n",
    "     globals()['X'+str(rank)+'_test']) = drop_row_match(globals()['X'+str(rank)+'_train'], \n",
    "                                                        globals()['X'+str(rank)+'_test'])\n",
    "\n",
    "# Simple Imputation + Standard Scaler\n",
    "    (globals()['X'+str(rank)+'_train'], \n",
    "     globals()['X'+str(rank)+'_test'], \n",
    "     globals()['X'+str(rank)+'_hidden'+str1]) = basic_modelprep('simple',\n",
    "                                                                globals()['X'+str(rank)+'_train'],\n",
    "                                                                globals()['X'+str(rank)+'_test'],\n",
    "                                                                globals()['X'+str(rank)+'_hidden'+str1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4ed380c-460d-4fe7-a45c-87176280d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_R2(rank):\n",
    "    lasso.fit(globals()['X'+str(rank)+'_train'],globals()['y'+str(rank)+'_train'])\n",
    "    print(lasso.score(globals()['X'+str(rank)+'_train'],globals()['y'+str(rank)+'_train']))\n",
    "    print(lasso.score(globals()['X'+str(rank)+'_test'],globals()['y'+str(rank)+'_test'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31003748-d857-438c-9bc7-f6227006548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoCV Rooted Mean Squared Error\n",
    "def get_RMSE(rank):\n",
    "    globals()['y'+str(rank)+'_pred'] = lasso.predict(globals()['X'+str(rank)+'_test'])\n",
    "    return mean_squared_error(globals()['y'+str(rank)+'_test'],globals()['y'+str(rank)+'_pred'], squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8de8c-dfa0-4747-a54b-0537b26b1f58",
   "metadata": {},
   "source": [
    "#### 3.3.2.1 Overall Qual = 0 (Ordinal rank 1-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df74ea69-575f-4a66-a8ea-a200657e5146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X0_train, X0_test, X0_hidden_OQ\n",
    "# Remove columns that do not exist in each of the 3 sets, and imputes and scales data\n",
    "standard_modifiers(rank = 0, str1 = 'OQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bbc2c8b-4384-46cc-aa72-efbf05ee4205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7822995551584105"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV(n_alphas = 200) # instantiate\n",
    "lasso_score = cross_val_score(lasso,X0_train,y0_train,cv=5)\n",
    "lasso_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e7e8ed7-9a88-4089-a30d-24c508ad793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8487943069293179\n",
      "0.7864742583961891\n"
     ]
    }
   ],
   "source": [
    "# Getting R^2 score for train and test sets\n",
    "get_R2(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "441aa183-763f-4b59-ab25-e39c4347d305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14550.191139758532"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_RMSE(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c474433f-2c24-430d-b4ef-f20b0c16a609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle y-pred result\n",
    "y0_pred_kaggle = lasso.predict(X0_hidden_OQ)\n",
    "len(y0_pred_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478edd0f-35d6-42e8-84fe-b77bc4a9b5c8",
   "metadata": {},
   "source": [
    "#### 3.3.2.2 Overall Qual = 1 (Ordinal rank 6-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8587ebd3-23d6-49e5-9fd9-7dc4650f0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1_train, X1_test, X1_hidden_OQ\n",
    "# Remove columns that do not exist in each of the 3 sets, and imputes and scales data\n",
    "standard_modifiers(rank = 1, str1 = 'OQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fba3a64b-db7a-4fa0-854c-bdef286a2ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8230411279437366"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV(n_alphas = 200, max_iter = 3000) # instantiate, increased iterations due to error\n",
    "lasso_score = cross_val_score(lasso,X1_train,y1_train,cv=5)\n",
    "lasso_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1459aa10-f0ba-470c-afd5-a06dc0900f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8809606040844872\n",
      "0.8135164314313986\n"
     ]
    }
   ],
   "source": [
    "get_R2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55ef3488-9ae6-4f36-980e-d04261d63e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18713.366659566753"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_RMSE(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "93d3f351-d0b8-49ff-82ad-a6f1806ae39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle y-pred result\n",
    "y1_pred_kaggle = lasso.predict(X1_hidden_OQ)\n",
    "len(y1_pred_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b060cdde-3f00-457f-8c64-a5e9c02ef641",
   "metadata": {},
   "source": [
    "#### 3.3.2.3 Overall Qual = 2 (Ordinal rank 8-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2f34cd7-64e3-4ca6-a861-d12d4a94d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2_train, X2_test, X2_hidden_OQ\n",
    "# Remove columns that do not exist in each of the 3 sets, and imputes and scales data\n",
    "standard_modifiers(rank = 2, str1 = 'OQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "828f8205-02af-4bd5-8837-1751278803d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13492870102478205"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV(n_alphas = 200, max_iter = 3000) # instantiate, increased iterations due to error\n",
    "lasso_score = cross_val_score(lasso,X2_train,y2_train,cv=5)\n",
    "lasso_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aa2246b6-a777-4a7f-8642-af67f496fe82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7926988117432899\n",
      "0.6885227477034966\n"
     ]
    }
   ],
   "source": [
    "get_R2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d44ae0d9-6729-45a2-bf80-d98e667d7758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42278.99240218937"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_RMSE(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba9fdef0-9b94-447a-9ebe-a1a5a2746ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle y-pred result\n",
    "y2_pred_kaggle = lasso.predict(X2_hidden_OQ)\n",
    "len(y2_pred_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdef466-2fa1-4bed-8320-a1d6948c6b93",
   "metadata": {},
   "source": [
    "#### 3.3.2.4 Combine Kaggle Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "515c7c31-3b94-43a3-87a0-d330d902a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline formatting of data for concatenating\n",
    "def format_kaggle_df(rank):\n",
    "    globals()['X'+str(rank)+'_tmp'] = X_hidden_OQ[X_hidden_OQ['Overall Qual'] == rank][['Overall Qual']]\n",
    "    globals()['X'+str(rank)+'_tmp']['Id'] = test_df['Id']\n",
    "    globals()['X'+str(rank)+'_tmp'] = globals()['X'+str(rank)+'_tmp'][['Id']]\n",
    "    globals()['X'+str(rank)+'_tmp']['SalePrice'] = globals()['y'+str(rank)+'_pred_kaggle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f34fed4-3e50-4b30-a3b7-992d5ebd801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format export for each step\n",
    "for i in [0,1,2]:\n",
    "    format_kaggle_df(i)\n",
    "\n",
    "# Combine data and export to .csv\n",
    "X_tmp = pd.concat([X0_tmp,X1_tmp,X2_tmp]).sort_index()\n",
    "kaggle_exp = X_tmp\n",
    "kaggle_exp.to_csv('Subm/lr_3_3_2_OverallQual(1to5_6to7_8to10).csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09849c3e-796d-4abc-9b07-75c7688c6bf2",
   "metadata": {},
   "source": [
    "#### Some notes on the result\n",
    "RMSE values for each of the subsets:\n",
    "1. Test RMSE(Overall Qual = 0): 14,550\n",
    "2. Test RMSE(Overall Qual = 1): 18,713\n",
    "3. Test RMSE(Overall Qual = 2): 42,278\n",
    "\n",
    "The results sort of support our conjecture - the buckets with more data performed better in the test set than bucket 2 (_8-10 score ordinal data_). On kaggle, the y-predicted values (_private score_) is around 21,493, which sort of lines up as the average performance of the 3 subsets.\n",
    "\n",
    "**Possible reasons for such a disparity could be:**\n",
    "1. The lack of enough training data for bucket 2;\n",
    "2. Perhaps also the correlation landscape for each subset is different as well.\n",
    "\n",
    "Let's look at the Overall Quality set again, but only take the top 20 correlated terms for each set.\n",
    "\n",
    "### 3.3.3 Overall Quality, only top 20 correlated features (Run 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fdb1a239-f39c-49e8-b86b-cc4182bfd482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking the dataframes from 3.3.2, Xi_OQ, yi_OQ, and Xi_hidden_OQ, which are already dummified and split\n",
    "# Step 1: Get top 20 correlated \n",
    "OQ_corrlist = pd.read_csv('datasets/3_3_3_corrlist.csv', index_col = 'Unnamed: 0')\n",
    "OQ_corrlist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "46aca443-577b-4fc4-a475-5b287dd32728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X and y variables (and X_hidden) to new scale factors\n",
    "X_OQ = X[:]\n",
    "X_hidden_OQ = X_hidden[:]\n",
    "\n",
    "# Reusing QQ_conv from 3.3.2\n",
    "X_OQ['Overall Qual'] = OQ_conv(X_OQ)\n",
    "X_hidden_OQ['Overall Qual'] = OQ_conv(X_hidden_OQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc1845f8-4358-4ead-a301-25376d28260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusing QQ_split from 3.3.2\n",
    "# Xi_OQ and Xi_hidden_OQ sets\n",
    "for i in [0,1,2]:\n",
    "    globals()['X'+str(i)+'_OQ'] = OQ_split(X_OQ,i) # Convert X subsets\n",
    "    globals()['X'+str(i)+'_hidden_OQ'] = OQ_split(X_hidden_OQ,i) # Convert X_hidden subsets\n",
    "\n",
    "#yi_OQ sets\n",
    "for i in [0,1,2]:\n",
    "    globals()['y'+str(i)+'_OQ'] = y[globals()['X'+str(i)+'_OQ'].index] # Split out y variables as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b125b38d-29fa-4928-999a-337136f546d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only top 20 correlated features\n",
    "for i in [0,1,2]:\n",
    "    corr_list = [j for j in list(OQ_corrlist['OQ'+str(i)]) \n",
    "                 if (j in globals()['X'+str(i)+'_OQ'].columns)&(j in globals()['X'+str(i)+'_hidden_OQ'].columns)]\n",
    "    globals()['X'+str(i)+'_OQ2'] = globals()['X'+str(i)+'_OQ'][corr_list]\n",
    "    globals()['X'+str(i)+'_hidden_OQ2'] = globals()['X'+str(i)+'_hidden_OQ'][corr_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e7777b6d-e71c-4cb2-9c5b-accaf7040665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split for all subsets\n",
    "for i in [0,1,2]:\n",
    "    (globals()['X'+str(i)+'_train'], \n",
    "    globals()['X'+str(i)+'_test'], \n",
    "    globals()['y'+str(i)+'_train'], \n",
    "    globals()['y'+str(i)+'_test']) = train_test_split(globals()['X'+str(i)+'_OQ2'],\n",
    "                                                     globals()['y'+str(i)+'_OQ'],\n",
    "                                                     random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520228a9-89bd-4afb-aa65-9def09b3bf78",
   "metadata": {},
   "source": [
    "#### 3.3.3.1 Overall Qual = 0, 20 Top Corr Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4ef594ac-3418-4bdf-be72-0fc4722f64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_modifiers(0,'OQ2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c190c4e-0653-415d-a8f1-dd597522513f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6975762042546677"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV(n_alphas = 200) # instantiate\n",
    "lasso_score = cross_val_score(lasso,X0_train,y0_train,cv=5)\n",
    "lasso_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "42d86779-a4ef-4a29-9586-a206f7ac7047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7282923297563675\n",
      "0.7024081489967064\n"
     ]
    }
   ],
   "source": [
    "# Getting R^2 score for train and test sets\n",
    "get_R2(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4d84cb9a-d346-443d-9c26-61f9e2c98566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17177.26819078559"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get test RMSE score\n",
    "get_RMSE(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a7c9df60-a575-4b66-95ea-1b74f3910e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle y-pred result\n",
    "y0_pred_kaggle = lasso.predict(X0_hidden_OQ2)\n",
    "len(y0_pred_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8290dad3-9457-42ad-8004-06e239f755ea",
   "metadata": {},
   "source": [
    "#### 3.3.3.2 Overall Qual = 1, 20 Top Corr Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "73a97e1d-e376-40e6-a13c-e06afce1febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_modifiers(1,'OQ2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9a1d61d9-2cc6-4d5e-a7ad-75539f8038bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7709888719477063"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV(n_alphas = 200) # instantiate\n",
    "lasso_score = cross_val_score(lasso,X1_train,y1_train,cv=5)\n",
    "lasso_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "547e236e-1ad4-4558-9404-d09e66aba5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795370880062981\n",
      "0.761482481360553\n"
     ]
    }
   ],
   "source": [
    "# Getting R^2 score for train and test sets\n",
    "get_R2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fbb67e1f-45a0-4a58-9220-89f8a4659719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21163.70906303993"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get test RMSE score\n",
    "get_RMSE(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c9416084-d59b-4b87-9c2c-dc39a6e3993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle y-pred result\n",
    "y1_pred_kaggle = lasso.predict(X1_hidden_OQ2)\n",
    "len(y1_pred_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35cb42f-acd7-47ee-831f-638f4597bd40",
   "metadata": {},
   "source": [
    "#### 3.3.3.3 Overall Qual = 2, 20 Top Corr Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "52613646-8634-485f-a797-077d5f2afbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_modifiers(2,'OQ2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3fe4dcc2-7c12-486e-9f68-9d10d9dde79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18738343687492737"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV(n_alphas = 200, max_iter = 3000) # instantiate\n",
    "lasso_score = cross_val_score(lasso,X2_train,y2_train,cv=5)\n",
    "lasso_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1fda1557-9f59-4e4a-9199-b96544dfd93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4795727947429209\n",
      "0.3869937058565498\n"
     ]
    }
   ],
   "source": [
    "# Getting R^2 score for train and test sets\n",
    "get_R2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aca5d731-94e8-4916-979d-c2c7f503dddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59312.18564548424"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get test RMSE score\n",
    "get_RMSE(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8228abf0-9e66-4720-ba16-fb441898acac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle y-pred result\n",
    "y2_pred_kaggle = lasso.predict(X2_hidden_OQ2)\n",
    "len(y2_pred_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa08860-378f-4e5d-869c-19f66d5143b8",
   "metadata": {},
   "source": [
    "#### 3.3.3.4 Combine Kaggle Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1efb0e2c-182a-4f79-9b69-6dd87519f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format export for each step\n",
    "for i in [0,1,2]:\n",
    "    format_kaggle_df(i)\n",
    "\n",
    "# Combine data and export to .csv\n",
    "X_tmp = pd.concat([X0_tmp,X1_tmp,X2_tmp]).sort_index()\n",
    "kaggle_exp = X_tmp\n",
    "kaggle_exp.to_csv('Subm/lr_3_3_2_OverallQual(1to5_6to7_8to10)_20topcorr.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0145bff8-274f-45ed-9429-5b12feca0e3c",
   "metadata": {},
   "source": [
    "#### 3.3.3.5 Conclusions on Overall Quality\n",
    "1. Unlike the model with all features, censoring out the best correlated features seems to have the opposite effect, increasing the variance on the model predictions and driving up the RMSE score.\n",
    "2. It is not represented in the notebook (due to time constraints), but when the number of variables is increased (in order of correlation to the particular segment), the performance of the model increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2e1a2-47c2-4fab-abd0-486d62fa95b8",
   "metadata": {},
   "source": [
    "## 4 Conclusions and Limitations\n",
    "The results from our optimisations seems to suggest that market segments do have differing wants, and thus segemented data react to various factors and variables differently. \n",
    "\n",
    "Segmented results do show promise in being good predictors, but more tuning is ultimately required in order to further tune the model's performance.\n",
    "\n",
    "**Final (best) run:**  \n",
    "LassoCV run on Overall Quality segmentation, run 6  \n",
    "Kaggle RMSE score: 21,493\n",
    "\n",
    "\n",
    "#### Limitations\n",
    "1. There was not enough time to do a full exploration of all the features within the dataset. With more tweaking, it is very likely that some of the features unexplored would have impacted the performance of the model to a larger degree.\n",
    "2. I chose not to focus on too many things when trying to optimise and explore the effects of the variables on the overall model, such as noise and (direct) inter-correlation analysis. These things ultimately have an impact on the accuracy of the model, and clearing the noise would definitely improve the performance as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a75f11-3297-4124-88a8-f209ebbee950",
   "metadata": {},
   "source": [
    "## 5 Future Improvements\n",
    "Due to time constraints, a lot of optimisations were not implemented. The following can be improved on should there come a time to further optimise the resultant models.\n",
    "\n",
    "1. Keep the naming of the models consistent and unique, allowing for the trained models to be called easily later on when needed.\n",
    "2. Some of the algorithms and transformations can be streamlined into more general, universal functions, with a little standardisation and tweaking.\n",
    "3. Use a cleaner naming convention for the runs and model variables, allowing for more powerful and generalised functions to be leveraged on.\n",
    "4. Creating an algorithm to sift through variables, perhaps 1-by-1, and their significance to each subset, might yield a more optimal result in most cases. There is a good chance that the variance seen in the performance of each segment (e.g. OQ = 0,1, and 2) is in part due to alot of variables creating noise and obscuring proper accuracy.\n",
    "5. Consider removing fields that may cause more noise than good for the model performance.\n",
    "6. Hyperparameter tuning could also be used to further optimise the models to get the best results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
